{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4ER17PSHfGat"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nabeel/Documents/Projects/Subsets/camera_code/dataiq_env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import random, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from os.path import exists\n",
    " \n",
    "from copy import deepcopy\n",
    "#from random import sample\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm\n",
    "from aum import DatasetWithIndex\n",
    "from aum import AUMCalculator\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_iq.dataiq_class import *\n",
    "from src.utils.utils import *\n",
    "from src.models.neuralnets import *\n",
    "from src.utils.data_loader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fLDMTlnNjSYA"
   },
   "outputs": [],
   "source": [
    "dataset = 'support'\n",
    "\n",
    "train_loader, train_data, X_train, y_train, X_test, y_test, X_train_pd, y_train_pd, X_test_pd, y_test_pd, nlabels, corr_vals, column_ids, df = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models and assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AOqMQXNT2h9k",
    "outputId": "017e460f-4d56-412d-dae9-e5e9760539dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]../src/models/neuralnets.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n",
      "/Users/nabeel/Documents/Projects/Subsets/camera_code/dataiq_env/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/nabeel/Documents/Projects/Subsets/camera_code/dataiq_env/lib/python3.7/site-packages/torch/nn/modules/module.py:1053: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.65455 | Acc: 0.567\n",
      "Validation loss decreased (inf --> 0.654553).  Saving model ...\n",
      "Epoch 002: | Loss: 0.57587 | Acc: 0.711\n",
      "Validation loss decreased (0.654553 --> 0.575874).  Saving model ...\n",
      "Epoch 003: | Loss: 0.55938 | Acc: 0.746\n",
      "Validation loss decreased (0.575874 --> 0.559384).  Saving model ...\n",
      "Epoch 004: | Loss: 0.55088 | Acc: 0.755\n",
      "Validation loss decreased (0.559384 --> 0.550881).  Saving model ...\n",
      "Epoch 005: | Loss: 0.54165 | Acc: 0.762\n",
      "Validation loss decreased (0.550881 --> 0.541650).  Saving model ...\n",
      "Epoch 006: | Loss: 0.53621 | Acc: 0.769\n",
      "Validation loss decreased (0.541650 --> 0.536207).  Saving model ...\n",
      "Epoch 007: | Loss: 0.52791 | Acc: 0.777\n",
      "Validation loss decreased (0.536207 --> 0.527907).  Saving model ...\n",
      "Epoch 008: | Loss: 0.52365 | Acc: 0.783\n",
      "Validation loss decreased (0.527907 --> 0.523647).  Saving model ...\n",
      "Epoch 009: | Loss: 0.51754 | Acc: 0.790\n",
      "Validation loss decreased (0.523647 --> 0.517535).  Saving model ...\n",
      "Epoch 010: | Loss: 0.51153 | Acc: 0.799\n",
      "Validation loss decreased (0.517535 --> 0.511526).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/models/neuralnets.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.65691 | Acc: 0.672\n",
      "Validation loss decreased (inf --> 0.656911).  Saving model ...\n",
      "Epoch 002: | Loss: 0.58797 | Acc: 0.709\n",
      "Validation loss decreased (0.656911 --> 0.587969).  Saving model ...\n",
      "Epoch 003: | Loss: 0.55060 | Acc: 0.747\n",
      "Validation loss decreased (0.587969 --> 0.550604).  Saving model ...\n",
      "Epoch 004: | Loss: 0.54175 | Acc: 0.756\n",
      "Validation loss decreased (0.550604 --> 0.541745).  Saving model ...\n",
      "Epoch 005: | Loss: 0.53677 | Acc: 0.761\n",
      "Validation loss decreased (0.541745 --> 0.536768).  Saving model ...\n",
      "Epoch 006: | Loss: 0.53056 | Acc: 0.768\n",
      "Validation loss decreased (0.536768 --> 0.530558).  Saving model ...\n",
      "Epoch 007: | Loss: 0.52557 | Acc: 0.778\n",
      "Validation loss decreased (0.530558 --> 0.525571).  Saving model ...\n",
      "Epoch 008: | Loss: 0.52208 | Acc: 0.784\n",
      "Validation loss decreased (0.525571 --> 0.522079).  Saving model ...\n",
      "Epoch 009: | Loss: 0.51613 | Acc: 0.792\n",
      "Validation loss decreased (0.522079 --> 0.516128).  Saving model ...\n",
      "Epoch 010: | Loss: 0.51251 | Acc: 0.796\n",
      "Validation loss decreased (0.516128 --> 0.512508).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/models/neuralnets.py:67: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  X = F.softmax(self.output(X))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.61714 | Acc: 0.636\n",
      "Validation loss decreased (inf --> 0.617145).  Saving model ...\n",
      "Epoch 002: | Loss: 0.56487 | Acc: 0.740\n",
      "Validation loss decreased (0.617145 --> 0.564869).  Saving model ...\n",
      "Epoch 003: | Loss: 0.54942 | Acc: 0.756\n",
      "Validation loss decreased (0.564869 --> 0.549421).  Saving model ...\n",
      "Epoch 004: | Loss: 0.53382 | Acc: 0.769\n",
      "Validation loss decreased (0.549421 --> 0.533815).  Saving model ...\n",
      "Epoch 005: | Loss: 0.52843 | Acc: 0.778\n",
      "Validation loss decreased (0.533815 --> 0.528431).  Saving model ...\n",
      "Epoch 006: | Loss: 0.52368 | Acc: 0.781\n",
      "Validation loss decreased (0.528431 --> 0.523680).  Saving model ...\n",
      "Epoch 007: | Loss: 0.51175 | Acc: 0.793\n",
      "Validation loss decreased (0.523680 --> 0.511753).  Saving model ...\n",
      "Epoch 008: | Loss: 0.50502 | Acc: 0.803\n",
      "Validation loss decreased (0.511753 --> 0.505019).  Saving model ...\n",
      "Epoch 009: | Loss: 0.49866 | Acc: 0.809\n",
      "Validation loss decreased (0.505019 --> 0.498657).  Saving model ...\n",
      "Epoch 010: | Loss: 0.49434 | Acc: 0.815\n",
      "Validation loss decreased (0.498657 --> 0.494342).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:46<03:04, 46.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.63487 | Acc: 0.681\n",
      "Validation loss decreased (inf --> 0.634866).  Saving model ...\n",
      "Epoch 002: | Loss: 0.58488 | Acc: 0.681\n",
      "Validation loss decreased (0.634866 --> 0.584876).  Saving model ...\n",
      "Epoch 003: | Loss: 0.56000 | Acc: 0.729\n",
      "Validation loss decreased (0.584876 --> 0.559998).  Saving model ...\n",
      "Epoch 004: | Loss: 0.54357 | Acc: 0.753\n",
      "Validation loss decreased (0.559998 --> 0.543570).  Saving model ...\n",
      "Epoch 005: | Loss: 0.53584 | Acc: 0.766\n",
      "Validation loss decreased (0.543570 --> 0.535839).  Saving model ...\n",
      "Epoch 006: | Loss: 0.53046 | Acc: 0.773\n",
      "Validation loss decreased (0.535839 --> 0.530457).  Saving model ...\n",
      "Epoch 007: | Loss: 0.52700 | Acc: 0.775\n",
      "Validation loss decreased (0.530457 --> 0.526996).  Saving model ...\n",
      "Epoch 008: | Loss: 0.52166 | Acc: 0.783\n",
      "Validation loss decreased (0.526996 --> 0.521658).  Saving model ...\n",
      "Epoch 009: | Loss: 0.51585 | Acc: 0.791\n",
      "Validation loss decreased (0.521658 --> 0.515853).  Saving model ...\n",
      "Epoch 010: | Loss: 0.51115 | Acc: 0.796\n",
      "Validation loss decreased (0.515853 --> 0.511151).  Saving model ...\n",
      "Epoch 001: | Loss: 0.65546 | Acc: 0.680\n",
      "Validation loss decreased (inf --> 0.655457).  Saving model ...\n",
      "Epoch 002: | Loss: 0.59005 | Acc: 0.701\n",
      "Validation loss decreased (0.655457 --> 0.590048).  Saving model ...\n",
      "Epoch 003: | Loss: 0.55366 | Acc: 0.748\n",
      "Validation loss decreased (0.590048 --> 0.553660).  Saving model ...\n",
      "Epoch 004: | Loss: 0.54258 | Acc: 0.751\n",
      "Validation loss decreased (0.553660 --> 0.542581).  Saving model ...\n",
      "Epoch 005: | Loss: 0.53735 | Acc: 0.758\n",
      "Validation loss decreased (0.542581 --> 0.537355).  Saving model ...\n",
      "Epoch 006: | Loss: 0.53354 | Acc: 0.765\n",
      "Validation loss decreased (0.537355 --> 0.533540).  Saving model ...\n",
      "Epoch 007: | Loss: 0.52831 | Acc: 0.774\n",
      "Validation loss decreased (0.533540 --> 0.528311).  Saving model ...\n",
      "Epoch 008: | Loss: 0.52521 | Acc: 0.777\n",
      "Validation loss decreased (0.528311 --> 0.525211).  Saving model ...\n",
      "Epoch 009: | Loss: 0.52300 | Acc: 0.782\n",
      "Validation loss decreased (0.525211 --> 0.522997).  Saving model ...\n",
      "Epoch 010: | Loss: 0.51911 | Acc: 0.786\n",
      "Validation loss decreased (0.522997 --> 0.519108).  Saving model ...\n",
      "Epoch 001: | Loss: 0.63445 | Acc: 0.641\n",
      "Validation loss decreased (inf --> 0.634453).  Saving model ...\n",
      "Epoch 002: | Loss: 0.57070 | Acc: 0.716\n",
      "Validation loss decreased (0.634453 --> 0.570702).  Saving model ...\n",
      "Epoch 003: | Loss: 0.54896 | Acc: 0.750\n",
      "Validation loss decreased (0.570702 --> 0.548964).  Saving model ...\n",
      "Epoch 004: | Loss: 0.53529 | Acc: 0.765\n",
      "Validation loss decreased (0.548964 --> 0.535293).  Saving model ...\n",
      "Epoch 005: | Loss: 0.52735 | Acc: 0.776\n",
      "Validation loss decreased (0.535293 --> 0.527348).  Saving model ...\n",
      "Epoch 006: | Loss: 0.51983 | Acc: 0.785\n",
      "Validation loss decreased (0.527348 --> 0.519825).  Saving model ...\n",
      "Epoch 007: | Loss: 0.51577 | Acc: 0.788\n",
      "Validation loss decreased (0.519825 --> 0.515772).  Saving model ...\n",
      "Epoch 008: | Loss: 0.50861 | Acc: 0.795\n",
      "Validation loss decreased (0.515772 --> 0.508606).  Saving model ...\n",
      "Epoch 009: | Loss: 0.49882 | Acc: 0.805\n",
      "Validation loss decreased (0.508606 --> 0.498822).  Saving model ...\n",
      "Epoch 010: | Loss: 0.49747 | Acc: 0.808\n",
      "Validation loss decreased (0.498822 --> 0.497466).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [01:31<02:17, 45.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.64927 | Acc: 0.625\n",
      "Validation loss decreased (inf --> 0.649267).  Saving model ...\n",
      "Epoch 002: | Loss: 0.57877 | Acc: 0.688\n",
      "Validation loss decreased (0.649267 --> 0.578769).  Saving model ...\n",
      "Epoch 003: | Loss: 0.55864 | Acc: 0.745\n",
      "Validation loss decreased (0.578769 --> 0.558643).  Saving model ...\n",
      "Epoch 004: | Loss: 0.54259 | Acc: 0.757\n",
      "Validation loss decreased (0.558643 --> 0.542594).  Saving model ...\n",
      "Epoch 005: | Loss: 0.53734 | Acc: 0.764\n",
      "Validation loss decreased (0.542594 --> 0.537339).  Saving model ...\n",
      "Epoch 006: | Loss: 0.53231 | Acc: 0.772\n",
      "Validation loss decreased (0.537339 --> 0.532313).  Saving model ...\n",
      "Epoch 007: | Loss: 0.52711 | Acc: 0.776\n",
      "Validation loss decreased (0.532313 --> 0.527110).  Saving model ...\n",
      "Epoch 008: | Loss: 0.52088 | Acc: 0.784\n",
      "Validation loss decreased (0.527110 --> 0.520878).  Saving model ...\n",
      "Epoch 009: | Loss: 0.51579 | Acc: 0.792\n",
      "Validation loss decreased (0.520878 --> 0.515793).  Saving model ...\n",
      "Epoch 010: | Loss: 0.51175 | Acc: 0.798\n",
      "Validation loss decreased (0.515793 --> 0.511752).  Saving model ...\n",
      "Epoch 001: | Loss: 0.64274 | Acc: 0.672\n",
      "Validation loss decreased (inf --> 0.642743).  Saving model ...\n",
      "Epoch 002: | Loss: 0.58047 | Acc: 0.707\n",
      "Validation loss decreased (0.642743 --> 0.580465).  Saving model ...\n",
      "Epoch 003: | Loss: 0.55367 | Acc: 0.742\n",
      "Validation loss decreased (0.580465 --> 0.553665).  Saving model ...\n",
      "Epoch 004: | Loss: 0.54259 | Acc: 0.753\n",
      "Validation loss decreased (0.553665 --> 0.542592).  Saving model ...\n",
      "Epoch 005: | Loss: 0.53662 | Acc: 0.765\n",
      "Validation loss decreased (0.542592 --> 0.536623).  Saving model ...\n",
      "Epoch 006: | Loss: 0.53182 | Acc: 0.773\n",
      "Validation loss decreased (0.536623 --> 0.531816).  Saving model ...\n",
      "Epoch 007: | Loss: 0.52693 | Acc: 0.774\n",
      "Validation loss decreased (0.531816 --> 0.526935).  Saving model ...\n",
      "Epoch 008: | Loss: 0.52258 | Acc: 0.785\n",
      "Validation loss decreased (0.526935 --> 0.522581).  Saving model ...\n",
      "Epoch 009: | Loss: 0.51771 | Acc: 0.790\n",
      "Validation loss decreased (0.522581 --> 0.517710).  Saving model ...\n",
      "Epoch 010: | Loss: 0.51301 | Acc: 0.794\n",
      "Validation loss decreased (0.517710 --> 0.513005).  Saving model ...\n",
      "Epoch 001: | Loss: 0.62813 | Acc: 0.682\n",
      "Validation loss decreased (inf --> 0.628128).  Saving model ...\n",
      "Epoch 002: | Loss: 0.57163 | Acc: 0.682\n",
      "Validation loss decreased (0.628128 --> 0.571627).  Saving model ...\n",
      "Epoch 003: | Loss: 0.56105 | Acc: 0.682\n",
      "Validation loss decreased (0.571627 --> 0.561054).  Saving model ...\n",
      "Epoch 004: | Loss: 0.55366 | Acc: 0.744\n",
      "Validation loss decreased (0.561054 --> 0.553655).  Saving model ...\n",
      "Epoch 005: | Loss: 0.55161 | Acc: 0.758\n",
      "Validation loss decreased (0.553655 --> 0.551608).  Saving model ...\n",
      "Epoch 006: | Loss: 0.54445 | Acc: 0.773\n",
      "Validation loss decreased (0.551608 --> 0.544452).  Saving model ...\n",
      "Epoch 007: | Loss: 0.53842 | Acc: 0.776\n",
      "Validation loss decreased (0.544452 --> 0.538417).  Saving model ...\n",
      "Epoch 008: | Loss: 0.53594 | Acc: 0.779\n",
      "Validation loss decreased (0.538417 --> 0.535941).  Saving model ...\n",
      "Epoch 009: | Loss: 0.52774 | Acc: 0.790\n",
      "Validation loss decreased (0.535941 --> 0.527740).  Saving model ...\n",
      "Epoch 010: | Loss: 0.52468 | Acc: 0.796\n",
      "Validation loss decreased (0.527740 --> 0.524678).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [02:17<01:31, 45.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.62820 | Acc: 0.682\n",
      "Validation loss decreased (inf --> 0.628198).  Saving model ...\n",
      "Epoch 002: | Loss: 0.57077 | Acc: 0.682\n",
      "Validation loss decreased (0.628198 --> 0.570769).  Saving model ...\n",
      "Epoch 003: | Loss: 0.56072 | Acc: 0.737\n",
      "Validation loss decreased (0.570769 --> 0.560719).  Saving model ...\n",
      "Epoch 004: | Loss: 0.55416 | Acc: 0.758\n",
      "Validation loss decreased (0.560719 --> 0.554164).  Saving model ...\n",
      "Epoch 005: | Loss: 0.54993 | Acc: 0.760\n",
      "Validation loss decreased (0.554164 --> 0.549932).  Saving model ...\n",
      "Epoch 006: | Loss: 0.54480 | Acc: 0.769\n",
      "Validation loss decreased (0.549932 --> 0.544802).  Saving model ...\n",
      "Epoch 007: | Loss: 0.54021 | Acc: 0.771\n",
      "Validation loss decreased (0.544802 --> 0.540209).  Saving model ...\n",
      "Epoch 008: | Loss: 0.53569 | Acc: 0.780\n",
      "Validation loss decreased (0.540209 --> 0.535694).  Saving model ...\n",
      "Epoch 009: | Loss: 0.53015 | Acc: 0.787\n",
      "Validation loss decreased (0.535694 --> 0.530154).  Saving model ...\n",
      "Epoch 010: | Loss: 0.52644 | Acc: 0.792\n",
      "Validation loss decreased (0.530154 --> 0.526437).  Saving model ...\n",
      "Epoch 001: | Loss: 0.64345 | Acc: 0.681\n",
      "Validation loss decreased (inf --> 0.643454).  Saving model ...\n",
      "Epoch 002: | Loss: 0.58114 | Acc: 0.693\n",
      "Validation loss decreased (0.643454 --> 0.581136).  Saving model ...\n",
      "Epoch 003: | Loss: 0.55324 | Acc: 0.748\n",
      "Validation loss decreased (0.581136 --> 0.553237).  Saving model ...\n",
      "Epoch 004: | Loss: 0.54231 | Acc: 0.760\n",
      "Validation loss decreased (0.553237 --> 0.542314).  Saving model ...\n",
      "Epoch 005: | Loss: 0.53733 | Acc: 0.764\n",
      "Validation loss decreased (0.542314 --> 0.537326).  Saving model ...\n",
      "Epoch 006: | Loss: 0.53305 | Acc: 0.770\n",
      "Validation loss decreased (0.537326 --> 0.533048).  Saving model ...\n",
      "Epoch 007: | Loss: 0.52965 | Acc: 0.773\n",
      "Validation loss decreased (0.533048 --> 0.529651).  Saving model ...\n",
      "Epoch 008: | Loss: 0.52445 | Acc: 0.782\n",
      "Validation loss decreased (0.529651 --> 0.524453).  Saving model ...\n",
      "Epoch 009: | Loss: 0.51970 | Acc: 0.786\n",
      "Validation loss decreased (0.524453 --> 0.519703).  Saving model ...\n",
      "Epoch 010: | Loss: 0.51486 | Acc: 0.790\n",
      "Validation loss decreased (0.519703 --> 0.514858).  Saving model ...\n",
      "Epoch 001: | Loss: 0.61099 | Acc: 0.683\n",
      "Validation loss decreased (inf --> 0.610986).  Saving model ...\n",
      "Epoch 002: | Loss: 0.56803 | Acc: 0.685\n",
      "Validation loss decreased (0.610986 --> 0.568033).  Saving model ...\n",
      "Epoch 003: | Loss: 0.54913 | Acc: 0.750\n",
      "Validation loss decreased (0.568033 --> 0.549128).  Saving model ...\n",
      "Epoch 004: | Loss: 0.53524 | Acc: 0.767\n",
      "Validation loss decreased (0.549128 --> 0.535241).  Saving model ...\n",
      "Epoch 005: | Loss: 0.52575 | Acc: 0.778\n",
      "Validation loss decreased (0.535241 --> 0.525750).  Saving model ...\n",
      "Epoch 006: | Loss: 0.52012 | Acc: 0.785\n",
      "Validation loss decreased (0.525750 --> 0.520121).  Saving model ...\n",
      "Epoch 007: | Loss: 0.51473 | Acc: 0.789\n",
      "Validation loss decreased (0.520121 --> 0.514734).  Saving model ...\n",
      "Epoch 008: | Loss: 0.50618 | Acc: 0.798\n",
      "Validation loss decreased (0.514734 --> 0.506184).  Saving model ...\n",
      "Epoch 009: | Loss: 0.49991 | Acc: 0.807\n",
      "Validation loss decreased (0.506184 --> 0.499909).  Saving model ...\n",
      "Epoch 010: | Loss: 0.49685 | Acc: 0.811\n",
      "Validation loss decreased (0.499909 --> 0.496847).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [03:02<00:45, 45.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.63245 | Acc: 0.663\n",
      "Validation loss decreased (inf --> 0.632445).  Saving model ...\n",
      "Epoch 002: | Loss: 0.57401 | Acc: 0.703\n",
      "Validation loss decreased (0.632445 --> 0.574008).  Saving model ...\n",
      "Epoch 003: | Loss: 0.55680 | Acc: 0.749\n",
      "Validation loss decreased (0.574008 --> 0.556805).  Saving model ...\n",
      "Epoch 004: | Loss: 0.54286 | Acc: 0.759\n",
      "Validation loss decreased (0.556805 --> 0.542860).  Saving model ...\n",
      "Epoch 005: | Loss: 0.53461 | Acc: 0.769\n",
      "Validation loss decreased (0.542860 --> 0.534612).  Saving model ...\n",
      "Epoch 006: | Loss: 0.52920 | Acc: 0.774\n",
      "Validation loss decreased (0.534612 --> 0.529204).  Saving model ...\n",
      "Epoch 007: | Loss: 0.52220 | Acc: 0.783\n",
      "Validation loss decreased (0.529204 --> 0.522197).  Saving model ...\n",
      "Epoch 008: | Loss: 0.51864 | Acc: 0.789\n",
      "Validation loss decreased (0.522197 --> 0.518645).  Saving model ...\n",
      "Epoch 009: | Loss: 0.51214 | Acc: 0.795\n",
      "Validation loss decreased (0.518645 --> 0.512139).  Saving model ...\n",
      "Epoch 010: | Loss: 0.50678 | Acc: 0.802\n",
      "Validation loss decreased (0.512139 --> 0.506784).  Saving model ...\n",
      "Epoch 001: | Loss: 0.63982 | Acc: 0.680\n",
      "Validation loss decreased (inf --> 0.639817).  Saving model ...\n",
      "Epoch 002: | Loss: 0.58071 | Acc: 0.696\n",
      "Validation loss decreased (0.639817 --> 0.580713).  Saving model ...\n",
      "Epoch 003: | Loss: 0.55644 | Acc: 0.748\n",
      "Validation loss decreased (0.580713 --> 0.556441).  Saving model ...\n",
      "Epoch 004: | Loss: 0.54326 | Acc: 0.757\n",
      "Validation loss decreased (0.556441 --> 0.543260).  Saving model ...\n",
      "Epoch 005: | Loss: 0.53850 | Acc: 0.761\n",
      "Validation loss decreased (0.543260 --> 0.538500).  Saving model ...\n",
      "Epoch 006: | Loss: 0.53490 | Acc: 0.764\n",
      "Validation loss decreased (0.538500 --> 0.534902).  Saving model ...\n",
      "Epoch 007: | Loss: 0.53071 | Acc: 0.771\n",
      "Validation loss decreased (0.534902 --> 0.530710).  Saving model ...\n",
      "Epoch 008: | Loss: 0.52836 | Acc: 0.774\n",
      "Validation loss decreased (0.530710 --> 0.528362).  Saving model ...\n",
      "Epoch 009: | Loss: 0.52390 | Acc: 0.782\n",
      "Validation loss decreased (0.528362 --> 0.523898).  Saving model ...\n",
      "Epoch 010: | Loss: 0.52161 | Acc: 0.783\n",
      "Validation loss decreased (0.523898 --> 0.521612).  Saving model ...\n",
      "Epoch 001: | Loss: 0.63010 | Acc: 0.604\n",
      "Validation loss decreased (inf --> 0.630103).  Saving model ...\n",
      "Epoch 002: | Loss: 0.56217 | Acc: 0.734\n",
      "Validation loss decreased (0.630103 --> 0.562167).  Saving model ...\n",
      "Epoch 003: | Loss: 0.54625 | Acc: 0.750\n",
      "Validation loss decreased (0.562167 --> 0.546248).  Saving model ...\n",
      "Epoch 004: | Loss: 0.53344 | Acc: 0.767\n",
      "Validation loss decreased (0.546248 --> 0.533441).  Saving model ...\n",
      "Epoch 005: | Loss: 0.52603 | Acc: 0.775\n",
      "Validation loss decreased (0.533441 --> 0.526031).  Saving model ...\n",
      "Epoch 006: | Loss: 0.51702 | Acc: 0.789\n",
      "Validation loss decreased (0.526031 --> 0.517025).  Saving model ...\n",
      "Epoch 007: | Loss: 0.50899 | Acc: 0.798\n",
      "Validation loss decreased (0.517025 --> 0.508993).  Saving model ...\n",
      "Epoch 008: | Loss: 0.50439 | Acc: 0.801\n",
      "Validation loss decreased (0.508993 --> 0.504393).  Saving model ...\n",
      "Epoch 009: | Loss: 0.50153 | Acc: 0.807\n",
      "Validation loss decreased (0.504393 --> 0.501535).  Saving model ...\n",
      "Epoch 010: | Loss: 0.49336 | Acc: 0.817\n",
      "Validation loss decreased (0.501535 --> 0.493362).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:48<00:00, 45.66s/it]\n"
     ]
    }
   ],
   "source": [
    "# Storage lists\n",
    "aums=[]\n",
    "\n",
    "jtts=[]\n",
    "\n",
    "datamaps=[]\n",
    "\n",
    "dataiqs=[]\n",
    "\n",
    "grads=[]\n",
    "\n",
    "n_feats=X_train.shape[1]\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "  from aum import AUMCalculator\n",
    "  delta=0.001\n",
    "  BATCH_SIZE=64\n",
    "  LEARNING_RATE = 0.001\n",
    "  EPOCHS=10\n",
    "\n",
    "  dataiq_list=[]\n",
    "    \n",
    "  nets = [Net1(input_size=n_feats, nlabels=nlabels),Net2(input_size=n_feats, nlabels=nlabels), Net3(input_size=n_feats, nlabels=nlabels)]\n",
    "  combos = [(0, 1), (0, 2), (1, 2)]\n",
    "    \n",
    "  checkpoint_list = []\n",
    "\n",
    "  overall_aum = []\n",
    "  overall_jtt = []\n",
    "\n",
    "  for i in range(len(nets)):\n",
    "    save_dir = '.'\n",
    "    aum_calculator = AUMCalculator(save_dir, compressed=True)\n",
    "    train_loader = DataLoader(dataset=DatasetWithIndex(train_data), batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    ckpt_nets = []\n",
    "    \n",
    "    net_idx = i\n",
    "    net = nets[net_idx]\n",
    "    net.to(device)\n",
    "    \n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "     \n",
    "    # Instantiate Data-IQ\n",
    "    dataiq = DataIQ_Torch(X=X_train , y=y_train, sparse_labels=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=2, delta=delta)\n",
    "\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch, sample_ids in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            sf = nn.LogSoftmax()\n",
    "            y_pred = net(X_batch)\n",
    "            records = aum_calculator.update(y_pred, y_batch.type(torch.int64), sample_ids.cpu().numpy())\n",
    "\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "\n",
    "            y_batch=y_batch.to(torch.int64)\n",
    "            loss = criterion(sf(y_pred), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += (predicted == y_batch).sum().item()/len(y_batch)\n",
    "        \n",
    "        # Log to Data-IQ\n",
    "        dataiq.on_epoch_end(net, device=device)\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "        early_stopping(epoch_loss/len(train_loader), net)\n",
    "\n",
    "        ckpt_nets.append(deepcopy(net))\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    checkpoint_list.append(ckpt_nets)\n",
    "    dataiq_list.append(dataiq)\n",
    "\n",
    "    net.load_state_dict(torch.load(\"checkpoint.pt\"))\n",
    "\n",
    "\n",
    "    #########\n",
    "    # AUM \n",
    "    #########\n",
    "    if exists('aum_values.csv'):\n",
    "      os.remove('aum_values.csv')\n",
    "\n",
    "    aum_calculator.finalize()\n",
    "    aum_df = pd.read_csv('aum_values.csv')\n",
    "    aum_scores = []\n",
    "    for i in range(aum_df.shape[0]):\n",
    "      aum_sc = aum_df[aum_df['sample_id']==i].aum.values[0]\n",
    "      aum_scores.append(aum_sc)\n",
    "    overall_aum.append(aum_scores)\n",
    "    \n",
    "    #########\n",
    "    # JTT\n",
    "    #########\n",
    "    jtt_vec = compute_jtt(X_train, y_train, net)\n",
    "    overall_jtt.append(jtt_vec)\n",
    "\n",
    "  \n",
    "  # Get the 2nd outputs since we care about spearman\n",
    "  _, spearman_corr = get_scores_generic(overall_aum, combos)\n",
    "  aums.append(spearman_corr)\n",
    "\n",
    "  _, spearman_corr = get_scores_generic(overall_jtt, combos)\n",
    "  jtts.append(spearman_corr)\n",
    "\n",
    "  _, spearman_corr = get_dataiq_scores(dataiq_list, combos, feat='variability')\n",
    "  datamaps.append(spearman_corr)\n",
    "\n",
    "  _, spearman_corr = get_dataiq_scores(dataiq_list, combos, feat='aleatoric')\n",
    "  dataiqs.append(spearman_corr)\n",
    "\n",
    "  _, spearman_corr = get_grad_scores(dataiq_list, combos)\n",
    "  grads.append(spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3Pu7BFdcu2U",
    "outputId": "8bdb4158-6db1-4d93-f022-4454b4da9cf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aum': 0.916190798530897,\n",
       " 'jtt': 0.7298764801900242,\n",
       " 'datamaps': 0.9047176065270961,\n",
       " 'dataiq': 0.948829636213856,\n",
       " 'gradn': 0.8754141693086199}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mean = {}\n",
    "\n",
    "results_mean['aum'] = np.mean(aums)\n",
    "\n",
    "results_mean['jtt'] = np.mean(jtts)\n",
    "\n",
    "results_mean['datamaps'] = np.mean(datamaps)\n",
    "\n",
    "results_mean['dataiq'] = np.mean(dataiqs)\n",
    "\n",
    "results_mean['gradn'] = np.mean(grads)\n",
    "\n",
    "results_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXEF3fJ0DWBP",
    "outputId": "67f0eaba-a156-4705-a1ac-bd92763205bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aum': 0.004698694963591204,\n",
       " 'jtt': 0.022488183177470037,\n",
       " 'datamaps': 0.013541113950829782,\n",
       " 'dataiq': 0.010409463769110547,\n",
       " 'gradn': 0.042576085289189}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_std= {}\n",
    "\n",
    "results_std['aum'] = np.std(aums)\n",
    "\n",
    "results_std['jtt'] = np.std(jtts)\n",
    "\n",
    "results_std['datamaps'] = np.std(datamaps)\n",
    "\n",
    "results_std['dataiq'] = np.std(dataiqs)\n",
    "\n",
    "results_std['gradn'] = np.std(grads)\n",
    "\n",
    "results_std"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dataiq_env",
   "language": "python",
   "name": "dataiq_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
